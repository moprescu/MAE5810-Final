{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import numpy as np\r\n",
    "import os\r\n",
    "import cv2\r\n",
    "from utils import *\r\n",
    "%matplotlib notebook"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1. Data Generation for YOLOv2"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#############################\r\n",
    "### Simulation Parameters ###\r\n",
    "#############################\r\n",
    "x_c = np.array([0, 20, 20])\r\n",
    "f = 10\r\n",
    "sensor_w = 6\r\n",
    "sensor_h = 4\r\n",
    "\r\n",
    "u_scale = 100/180*np.pi\r\n",
    "t_max = 10\r\n",
    "fps = 10\r\n",
    "x_max = 40"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def yolo_data_generation(f, ax2, vehicles, sensor_w, sensor_h, dpi=100, \r\n",
    "                         file_template=\"Virtual_FOV_frame_{0}_it_0.{1}\", \r\n",
    "                         file_path=\".\\\\yolov3\\\\object-detection\\\\raw_data\"):\r\n",
    "    # Get window extent\r\n",
    "    extent = ax2.get_window_extent().transformed(fig.dpi_scale_trans.inverted())\r\n",
    "    extent.x0 = extent.x0 + 0.02\r\n",
    "    extent.x1 = extent.x1 - 0.02\r\n",
    "    extent.y0 = extent.y0 + 0.02\r\n",
    "    extent.y1 = extent.y1 - 0.02\r\n",
    "    extent_delta_x = (extent.x1 - extent.x0) * dpi\r\n",
    "    extent_delta_y = (extent.y1 - extent.y0) * dpi\r\n",
    "    # Get file paths\r\n",
    "    image_path = os.path.join(file_path, file_template.format(f, \"jpg\"))\r\n",
    "    labels_path = os.path.join(file_path, file_template.format(f, \"txt\"))\r\n",
    "    # Save image\r\n",
    "    ax2.figure.savefig(image_path, dpi=dpi, bbox_inches=extent)\r\n",
    "    # Get vehicle bounding boxes in yolo format\r\n",
    "    f = open(labels_path, 'w')\r\n",
    "    for vehicle in vehicles:\r\n",
    "        vv_corners = vehicle.vv_corners.get_offsets()\r\n",
    "        box_center_x = (np.min(vv_corners[:, 0])+np.max(vv_corners[:, 0]))/2\r\n",
    "        box_center_y = (np.min(vv_corners[:, 1])+np.max(vv_corners[:, 1]))/2\r\n",
    "        box_width_x = (np.max(vv_corners[:, 0])-np.min(vv_corners[:, 0]))*1.07 # Margin\r\n",
    "        box_height_y = (np.max(vv_corners[:, 1])-np.min(vv_corners[:, 1]))*1.07 # Margin\r\n",
    "        # Do something only if box in FOV\r\n",
    "        if (box_center_x > -sensor_w/2) and (box_center_x <= sensor_w/2) and (box_center_y > -sensor_h/2) and (box_center_y < sensor_h/2):\r\n",
    "            # box center is in FOV\r\n",
    "            # Check if box is clipped somewhere\r\n",
    "            if box_center_x + box_width_x/2 > sensor_w/2:\r\n",
    "                delta_clip = (box_center_x + box_width_x/2) - sensor_w/2\r\n",
    "                box_center_x -= delta_clip/2\r\n",
    "                box_width_x -= delta_clip\r\n",
    "            if box_center_x + box_width_x/2 < -sensor_w/2:\r\n",
    "                delta_clip = - sensor_w/2 - (box_center_x + box_width_x/2)\r\n",
    "                box_center_x += delta_clip/2\r\n",
    "                box_width_x -= delta_clip\r\n",
    "            if box_center_y + box_height_y/2 > sensor_h/2:\r\n",
    "                delta_clip = (box_center_y + box_height_y/2) - sensor_h/2\r\n",
    "                box_center_y -= delta_clip/2\r\n",
    "                box_height_y -= delta_clip\r\n",
    "            if box_center_y + box_height_y/2 < -sensor_h/2:\r\n",
    "                delta_clip = - sensor_h/2 - (box_center_y + box_height_y/2)\r\n",
    "                box_center_y += delta_clip/2\r\n",
    "                box_height_y -= delta_clip\r\n",
    "            # Now convert to image coordinates\r\n",
    "            box_center_x_img = box_center_x / sensor_w + 1/2\r\n",
    "            box_center_y_img = 1 - (box_center_y / sensor_h + 1/2)\r\n",
    "            box_width_x_img = box_width_x/sensor_w\r\n",
    "            box_height_y_img = box_height_y/sensor_h\r\n",
    "            f.write(f\"0 {box_center_x_img} {box_center_y_img} {box_width_x_img} {box_height_y_img}\\n\")\r\n",
    "    f.close()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def update(f, suffix=\"\"):\r\n",
    "    if f == 0:\r\n",
    "        phi_t = phi_0\r\n",
    "    t = f/fps\r\n",
    "    if f >= t_max*fps:\r\n",
    "        return\r\n",
    "    psi_t = psi_0 + np.sum(phi_dots[:f, 0])/fps\r\n",
    "    phi_t = phi_0 + np.sum(phi_dots[:f, 1])/fps\r\n",
    "    # Update objects\r\n",
    "    camera_fov.update_FOV(psi=psi_t, phi=phi_t)\r\n",
    "    for v in vehicles:\r\n",
    "        v.update_vehicle(t)\r\n",
    "        v.update_vehicle_virtual(camera_fov, t)\r\n",
    "    for b in background:\r\n",
    "        b.update_vehicle_virtual(camera_fov)\r\n",
    "    # Update angle plot\r\n",
    "    psi_data[1, f] = psi_t\r\n",
    "    psi_line.set_data(psi_data[:, :(f+1)])\r\n",
    "    phi_data[1, f] = phi_t\r\n",
    "    phi_line.set_data(phi_data[:, :(f+1)])\r\n",
    "    # Update u_plot\r\n",
    "    psi_dot, phi_dot = psi_phi_dot(t, t_max)\r\n",
    "    u1_data[1, f] = psi_dot/u_scale\r\n",
    "    u1_line.set_data(u1_data[:, :(f+1)])\r\n",
    "    u2_data[1, f] = phi_dot/u_scale\r\n",
    "    u2_line.set_data(u2_data[:, :(f+1)])\r\n",
    "    if (f+1)%fps == 0:\r\n",
    "        title.set_text(\r\n",
    "            'PT Camera Simulation, time={t:0.0f}s\\nApplication: {app_name}'.format(t=t, app_name=app_name))\r\n",
    "    file_path = \".\\\\yolov3\\\\object-detection\\\\raw_data\"\r\n",
    "    if not os.path.exists(file_path):\r\n",
    "        os.makedirs(file_path)\r\n",
    "    # Save virtual FOV figures\r\n",
    "    yolo_data_generation(f, ax2, vehicles+background, sensor_w, sensor_h, dpi=100, \r\n",
    "                         file_template=\"Virtual_FOV_frame_{0}_\"+f\"{suffix}\"+\".{1}\", \r\n",
    "                         file_path=\".\\\\yolov3\\\\object-detection\\\\raw_data\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "sim_configs = [\r\n",
    "    [\r\n",
    "        [\r\n",
    "            lambda ax, ax2: LinearVehicle(ax, ax2, v_l=2, v_w=4, vel_dir=np.array([2, 1.4])*4, color='gray'),\r\n",
    "            lambda ax, ax2: LinearVehicle(ax, ax2, v_l=2, v_w=4, y_offset=40, vel_dir=np.array([1, -1])*2, color='burlywood'),\r\n",
    "            lambda ax, ax2: LinearVehicle(ax, ax2, v_l=2, v_w=4, x_offset=20, y_offset=40,  vel_dir=np.array([1, -1])*2, color='black'),\r\n",
    "            lambda ax, ax2: LinearVehicle(ax, ax2, v_l=2, v_w=4, x_offset=25, y_offset=0,  vel_dir=np.array([-1, 4]), color='saddlebrown'),\r\n",
    "        ],\r\n",
    "        [\r\n",
    "            lambda ax, ax2: BackgroundObject(ax, ax2, v_l=4, v_w=4, x_offset=10, y_offset=10, vel_dir=np.array([0, 0]), color=\"darkgreen\"),\r\n",
    "            lambda ax, ax2: BackgroundObject(ax, ax2, v_l=3, v_w=4, x_offset=10, y_offset=30, vel_dir=np.array([0, 0]), color=\"slategray\"),\r\n",
    "            lambda ax, ax2: BackgroundObject(ax, ax2, v_l=3, v_w=4, x_offset=30, y_offset=10,  vel_dir=np.array([0, 1]), color=\"sienna\"),\r\n",
    "            lambda ax, ax2: BackgroundObject(ax, ax2, v_l=6, v_w=4, x_offset=25, y_offset=25,  vel_dir=np.array([0, 0]), color=\"steelblue\"),\r\n",
    "        ],\r\n",
    "        [\r\n",
    "            {\"suffix\":\"conf_0_it_0\", \"psi_0\": 0, \"phi_0\": np.pi-np.pi/5, \r\n",
    "             \"psi_phi_dot\": lambda t, t_max: (2*np.pi/(t_max), 0) if t <= t_max/2 else (-2*np.pi/(t_max-1/2), 0)},\r\n",
    "            {\"suffix\":\"conf_0_it_1\", \"psi_0\": np.pi/3, \"phi_0\": np.pi-np.pi/3.6, \r\n",
    "             \"psi_phi_dot\": lambda t, t_max: (2*np.pi/3/(t_max), 0) if t <= t_max/2 else (-2*np.pi/3/(t_max-1/2), 0)},\r\n",
    "            {\"suffix\":\"conf_0_it_2\", \"psi_0\": np.pi/2, \"phi_0\": np.pi-np.pi/15, \r\n",
    "             \"psi_phi_dot\": lambda t, t_max: (0, -2*np.pi/4/(t_max)) if t <= t_max/2 else (0, 2*np.pi/4/(t_max-1/2))}\r\n",
    "        ]\r\n",
    "    ],\r\n",
    "    [\r\n",
    "        [\r\n",
    "            lambda ax, ax2: LinearVehicle(ax, ax2, v_l=2, v_w=4, x_offset=5, y_offset=20, vel_dir=np.array([1, 0.1])*4, color='gray'),\r\n",
    "            lambda ax, ax2: LinearVehicle(ax, ax2, v_l=2, v_w=4, x_offset=20, y_offset=0, vel_dir=np.array([1, 4])*1.5, color='burlywood'),\r\n",
    "            lambda ax, ax2: LinearVehicle(ax, ax2, v_l=2, v_w=4, x_offset=40, y_offset=10,  vel_dir=np.array([-1.2, 1])*2, color='black'),\r\n",
    "            lambda ax, ax2: LinearVehicle(ax, ax2, v_l=2, v_w=4, x_offset=25, y_offset=0,  vel_dir=np.array([-1, 4]), color='saddlebrown'),\r\n",
    "        ],\r\n",
    "        [\r\n",
    "            lambda ax, ax2: BackgroundObject(ax, ax2, v_l=2, v_w=4, x_offset=20, y_offset=30, vel_dir=np.array([0, 0]), color=\"darkgreen\"),\r\n",
    "            lambda ax, ax2: BackgroundObject(ax, ax2, v_l=5, v_w=2, x_offset=30, y_offset=5, vel_dir=np.array([0, 0]), color=\"slategray\"),\r\n",
    "            lambda ax, ax2: BackgroundObject(ax, ax2, v_l=3, v_w=4, x_offset=30, y_offset=25,  vel_dir=np.array([0.5, 1]), color=\"sienna\"),\r\n",
    "            lambda ax, ax2: BackgroundObject(ax, ax2, v_l=5, v_w=5, x_offset=10, y_offset=15,  vel_dir=np.array([1, 1]), color=\"steelblue\"),\r\n",
    "        ],\r\n",
    "        [\r\n",
    "            {\"suffix\":\"conf_1_it_0\", \"psi_0\": 0, \"phi_0\": np.pi-np.pi/5, \r\n",
    "             \"psi_phi_dot\": lambda t, t_max: (2*np.pi/(t_max), 0) if t <= t_max/2 else (-2*np.pi/(t_max-1/2), 0)},\r\n",
    "            {\"suffix\":\"conf_1_it_1\", \"psi_0\": np.pi/3, \"phi_0\": np.pi-np.pi/3.6, \r\n",
    "             \"psi_phi_dot\": lambda t, t_max: (2*np.pi/3/(t_max), 0) if t <= t_max/2 else (-2*np.pi/3/(t_max-1/2), 0)},\r\n",
    "            {\"suffix\":\"conf_1_it_2\", \"psi_0\": np.pi/2, \"phi_0\": np.pi-np.pi/15, \r\n",
    "             \"psi_phi_dot\": lambda t, t_max: (0, -2*np.pi/4/(t_max)) if t <= t_max/2 else (0, 2*np.pi/4/(t_max-1/2))}\r\n",
    "        ]\r\n",
    "    ],\r\n",
    "    [\r\n",
    "        [\r\n",
    "            lambda ax, ax2: LinearVehicle(ax, ax2, v_l=2, v_w=4, x_offset=0, y_offset=30, vel_dir=np.array([1, -1.1])*2, color='gray'),\r\n",
    "            lambda ax, ax2: LinearVehicle(ax, ax2, v_l=2, v_w=4, x_offset=20, y_offset=0, vel_dir=np.array([1, 4])*1.5, color='burlywood'),\r\n",
    "            lambda ax, ax2: LinearVehicle(ax, ax2, v_l=2, v_w=4, x_offset=40, y_offset=10,  vel_dir=np.array([-1.2, 1])*3, color='black'),\r\n",
    "            lambda ax, ax2: LinearVehicle(ax, ax2, v_l=2, v_w=4, x_offset=15, y_offset=10,  vel_dir=np.array([1, 1])*2, color='saddlebrown'),\r\n",
    "        ],\r\n",
    "        [\r\n",
    "            lambda ax, ax2: BackgroundObject(ax, ax2, v_l=4, v_w=4, x_offset=5, y_offset=30, vel_dir=np.array([1, 1]), color=\"darkgreen\"),\r\n",
    "            lambda ax, ax2: BackgroundObject(ax, ax2, v_l=5, v_w=2, x_offset=10, y_offset=10, vel_dir=np.array([1, 0.1]), color=\"slategray\"),\r\n",
    "            lambda ax, ax2: BackgroundObject(ax, ax2, v_l=2, v_w=4, x_offset=30, y_offset=10,  vel_dir=np.array([0, 1]), color=\"sienna\"),\r\n",
    "            lambda ax, ax2: BackgroundObject(ax, ax2, v_l=3, v_w=6, x_offset=15, y_offset=20,  vel_dir=np.array([1, 0]), color=\"steelblue\"),\r\n",
    "        ],\r\n",
    "        [\r\n",
    "            {\"suffix\":\"conf_2_it_0\", \"psi_0\": 0, \"phi_0\": np.pi-np.pi/5, \r\n",
    "             \"psi_phi_dot\": lambda t, t_max: (2*np.pi/(t_max), 0) if t <= t_max/2 else (-2*np.pi/(t_max-1/2), 0)},\r\n",
    "            {\"suffix\":\"conf_2_it_1\", \"psi_0\": np.pi/3, \"phi_0\": np.pi-np.pi/3.6, \r\n",
    "             \"psi_phi_dot\": lambda t, t_max: (2*np.pi/3/(t_max), 0) if t <= t_max/2 else (-2*np.pi/3/(t_max-1/2), 0)},\r\n",
    "            {\"suffix\":\"conf_2_it_2\", \"psi_0\": np.pi/2, \"phi_0\": np.pi-np.pi/15, \r\n",
    "             \"psi_phi_dot\": lambda t, t_max: (0, -2*np.pi/4/(t_max)) if t <= t_max/2 else (0, 2*np.pi/4/(t_max-1/2))}\r\n",
    "        ]\r\n",
    "    ]\r\n",
    "]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "###########################\r\n",
    "### Wildlife Simulation ###\r\n",
    "###########################\r\n",
    "\r\n",
    "np.random.seed(5)\r\n",
    "app_name = \"Wildlife tracking\"\r\n",
    "\r\n",
    "config_id = 2\r\n",
    "it_id = 2\r\n",
    "\r\n",
    "conf_dict = sim_configs[config_id][2][it_id]\r\n",
    "\r\n",
    "psi_0 = conf_dict[\"psi_0\"]\r\n",
    "phi_0 = conf_dict[\"phi_0\"]\r\n",
    "\r\n",
    "fig, ax, ax2, camera_fov, psi_line, psi_data, phi_line, \\\r\n",
    "phi_data, u1_line, u1_data, u2_line, u2_data = animation_setup(sensor_w, sensor_h, f, x_c, psi_0, phi_0, t_max, fps)\r\n",
    "\r\n",
    "vehicles = [vehicle_f(ax,ax2) for vehicle_f in sim_configs[config_id][0]]\r\n",
    "background = [background_f(ax,ax2) for background_f in sim_configs[config_id][1]]\r\n",
    "\r\n",
    "psi_phi_dot = conf_dict[\"psi_phi_dot\"]\r\n",
    "\r\n",
    "phi_dots = np.array([psi_phi_dot(f/fps, t_max) for f in np.arange(fps*t_max)])\r\n",
    "title = ax.set_title('PT Camera Simulation, time=0s\\nApplication: {}'.format(app_name))\r\n",
    "\r\n",
    "# Animate FOV\r\n",
    "ani = animation.FuncAnimation(fig, update, t_max*fps+10, fargs=(conf_dict[\"suffix\"],), interval=10, blit=True, repeat=False)\r\n",
    "#ani.save('PT_camera_simulation_wildlife_16_9.gif', fps=fps)#, writer='imagemagick')\r\n",
    "#plt.savefig(\"PT_camera_simulation_wildlife_snapshot2.png\", dpi=300, bbox_inches=\"tight\")\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Cleanup\r\n",
    "non_empty = 0\r\n",
    "suffixes = [\"conf_0_it_0\", \"conf_0_it_1\", \"conf_0_it_2\", \r\n",
    "            \"conf_1_it_0\", \"conf_1_it_1\", \"conf_1_it_2\", \r\n",
    "            \"conf_2_it_0\", \"conf_2_it_1\", \"conf_2_it_2\"]\r\n",
    "for suffix in suffixes:\r\n",
    "    for ff in range(100):\r\n",
    "        bboxes = np.loadtxt(f'.\\\\yolov3\\\\object-detection\\\\raw_data\\\\Virtual_FOV_frame_{ff}_{suffix}.txt')\r\n",
    "        if bboxes.size!=0:\r\n",
    "            non_empty += 1\r\n",
    "        if bboxes.size==0:\r\n",
    "            os.remove(f'.\\\\yolov3\\\\object-detection\\\\raw_data\\\\Virtual_FOV_frame_{ff}_{suffix}.txt')\r\n",
    "            os.remove(f'.\\\\yolov3\\\\object-detection\\\\raw_data\\\\Virtual_FOV_frame_{ff}_{suffix}.jpg')"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Create train and test metadata\r\n",
    "train_file = f\".\\\\yolov3\\\\object-detection\\\\train.txt\"\r\n",
    "test_file = f\".\\\\yolov3\\\\object-detection\\\\test.txt\"\r\n",
    "path_template = \"/content/object-detection/raw_data/{0}.jpg\"\r\n",
    "suffixes = [\"conf_0_it_0\", \"conf_0_it_1\", \"conf_0_it_2\", \r\n",
    "            \"conf_1_it_0\", \"conf_1_it_1\", \"conf_1_it_2\"] \r\n",
    "f = open(train_file, 'w')\r\n",
    "for suffix in suffixes:\r\n",
    "    for ff in range(100):\r\n",
    "        file_path = f\".\\\\yolov3\\\\object-detection\\\\raw_data\\\\Virtual_FOV_frame_{ff}_{suffix}.jpg\"\r\n",
    "        if os.path.exists(file_path):\r\n",
    "            img_name = f\"Virtual_FOV_frame_{ff}_{suffix}\"\r\n",
    "            f.write(path_template.format(img_name)+'\\n')\r\n",
    "f.close()\r\n",
    "suffixes = [\"conf_2_it_0\", \"conf_2_it_1\", \"conf_2_it_2\"]\r\n",
    "f = open(test_file, 'w')\r\n",
    "for suffix in suffixes:\r\n",
    "    for ff in range(100):\r\n",
    "        file_path = f\".\\\\yolov3\\\\object-detection\\\\raw_data\\\\Virtual_FOV_frame_{ff}_{suffix}.jpg\"\r\n",
    "        if os.path.exists(file_path):\r\n",
    "            img_name = f\"Virtual_FOV_frame_{ff}_{suffix}\"\r\n",
    "            f.write(path_template.format(img_name)+'\\n')\r\n",
    "f.close()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2. YOLO Testing"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "%matplotlib notebook"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Test image transformations\r\n",
    "ff = 16\r\n",
    "suffix = \"conf_2_it_1\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "frame = cv2.imread(f'.\\\\yolov3\\\\object-detection\\\\raw_data\\\\Virtual_FOV_frame_{ff}_{suffix}.jpg')\r\n",
    "frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\r\n",
    "bboxes = np.loadtxt(f'.\\\\yolov3\\\\object-detection\\\\raw_data\\\\Virtual_FOV_frame_{ff}_{suffix}.txt')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "bboxes"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "if len(bboxes.shape) == 1:\r\n",
    "    _, xc, yc, w, h = bboxes * np.array([0, 491, 285, 491, 285])\r\n",
    "    cv2.rectangle(frame, (int(xc-w/2), int(yc-h/2)), (int(xc+w/2), int(yc+h/2)), (0, 255, 0), 1)\r\n",
    "    plt.scatter([xc], [yc], color='black', s=1)\r\n",
    "else:\r\n",
    "    for bbox in bboxes:\r\n",
    "        _, xc, yc, w, h = bbox * np.array([0, 491, 285, 491, 285])\r\n",
    "        cv2.rectangle(frame, (int(xc-w/2), int(yc-h/2)), (int(xc+w/2), int(yc+h/2)), (0, 255, 0), 1)\r\n",
    "        plt.scatter([xc], [yc], color='black', s=1)\r\n",
    "plt.imshow(frame)\r\n",
    "#plt.axis('off')\r\n",
    "plt.xticks([])\r\n",
    "plt.yticks([])\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "%matplotlib notebook"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "net = cv2.dnn.readNet('yolov2-voc_last.weights', 'yolov2-voc.cfg')\r\n",
    "layer_names = net.getLayerNames()\r\n",
    "output_layers = [layer_names[i-1] for i in net.getUnconnectedOutLayers()]\r\n",
    "frame = cv2.imread('yolov3/object-detection/raw_data/Virtual_FOV_frame_0_conf_0_it_1.jpg')\r\n",
    "frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\r\n",
    "blob = cv2.dnn.blobFromImage(frame, 1/255, (416, 416), (0, 0, 0), crop=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "net.setInput(blob)\r\n",
    "outs = net.forward(output_layers)\r\n",
    "height, width, channels = frame.shape"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class_ids = []\r\n",
    "confidences = []\r\n",
    "boxes = []\r\n",
    "centers = []\r\n",
    "for out in outs:\r\n",
    "    for detection in out:\r\n",
    "        confidence = detection[5]\r\n",
    "        if confidence > 0.7:\r\n",
    "            print(confidence)\r\n",
    "            print((detection[0]-1/2)*6)\r\n",
    "            print((1/2-detection[1])*4)\r\n",
    "            center_x = int(detection[0] * width)\r\n",
    "            center_y = int(detection[1] * height)\r\n",
    "            w = int(detection[2] * width)\r\n",
    "            h = int(detection[3] * height)\r\n",
    "            x = int(center_x - w / 2)\r\n",
    "            y = int(center_y - h / 2)\r\n",
    "            boxes.append([x, y, w, h])\r\n",
    "            confidences.append(float(confidence))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "for i, bbox in enumerate(boxes):\r\n",
    "    x, y, w, h = bbox\r\n",
    "    cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 1)\r\n",
    "    plt.scatter([x+w/2], [y+h/2], color='black', s=1)\r\n",
    "    textbox = plt.text(x, y-3, f\"Object: {confidences[i]:0.2f}, ID:{i}\", color='black', backgroundcolor='green', fontsize=7)\r\n",
    "    textbox.set_bbox(dict(facecolor='green', pad=0.1, edgecolor='green'))\r\n",
    "plt.imshow(frame)\r\n",
    "#plt.axis('off')\r\n",
    "plt.xticks([])\r\n",
    "plt.yticks([])\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}